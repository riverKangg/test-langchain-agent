# ë©€í‹°ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•œ 1ì¸ ì°½ì—…ì•„ì´í…œ êµ¬ìƒí•´ì¤˜.

# brainstorm_assistant/main.py
from graph.workflow import build_graph

if __name__ == "__main__":
    chain = build_graph()
    user_input = input("ğŸ’¬ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    result = chain.invoke({"input": user_input})
    print("\nğŸ§  ë¸Œë ˆì¸ìŠ¤í† ë° ê²°ê³¼:\n")
    print(result['summary'])


# brainstorm_assistant/agents/__init__.py
# ë¹ˆ íŒŒì¼ (íŒ¨í‚¤ì§€ ì¸ì‹ìš©)


# brainstorm_assistant/agents/expander.py
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

llm = ChatOpenAI()

def expand_idea(state):
    # prompt = PromptTemplate.from_file("prompts/expander.txt", input_variables=["input"])
    # return {"expanded": llm(prompt.format(input=state["input"]))}

    prompt = PromptTemplate.from_file("prompts/expander.txt", input_variables=["input"])
    formatted = prompt.format(input=state["input"])
    response = llm.invoke(formatted)
    return {"expanded": response.content}


# brainstorm_assistant/agents/critic.py
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

llm = ChatOpenAI()

def criticize_idea(state):
    prompt = PromptTemplate.from_file("prompts/critic.txt", input_variables=["expanded"])
    return {"critique": llm(prompt.format(expanded=state["expanded"]))}


# brainstorm_assistant/agents/mediator.py
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

llm = ChatOpenAI()

def mediate_opinions(state):
    prompt = PromptTemplate.from_file("prompts/mediator.txt", input_variables=["expanded", "critique"])
    return {"mediated": llm(prompt.format(expanded=state["expanded"], critique=state["critique"]))}


# brainstorm_assistant/agents/summarizer.py
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

llm = ChatOpenAI()

def summarize_all(state):
    prompt = PromptTemplate.from_file("prompts/summarizer.txt", input_variables=["expanded", "critique", "mediated"])
    summary = llm(prompt.format(**state))
    return {"summary": summary}


# brainstorm_assistant/graph/__init__.py
# ë¹ˆ íŒŒì¼ (íŒ¨í‚¤ì§€ ì¸ì‹ìš©)


# brainstorm_assistant/graph/workflow.py
from langgraph.graph import StateGraph, END
from langchain.schema import RunnableLambda
from agents.expander import expand_idea
from agents.critic import criticize_idea
from agents.mediator import mediate_opinions
from agents.summarizer import summarize_all

def build_graph():
    graph = StateGraph()
    graph.add_node("Expand", RunnableLambda(expand_idea))
    graph.add_node("Critic", RunnableLambda(criticize_idea))
    graph.add_node("Mediator", RunnableLambda(mediate_opinions))
    graph.add_node("Summarizer", RunnableLambda(summarize_all))

    graph.set_entry_point("Expand")
    graph.add_edge("Expand", "Critic")
    graph.add_edge("Critic", "Mediator")
    graph.add_edge("Mediator", "Summarizer")
    graph.add_edge("Summarizer", END)

    return graph.compile()


# brainstorm_assistant/prompts/expander.txt
ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"""
{input}
"""
ì´ ì•„ì´ë””ì–´ë¥¼ í˜„ì‹¤ì ì´ê³  ì°½ì˜ì ì¸ ë°©í–¥ìœ¼ë¡œ 3ê°€ì§€ ì´ìƒ í™•ì¥í•´ì£¼ì„¸ìš”.


# brainstorm_assistant/prompts/critic.txt
ë‹¤ìŒì€ í™•ì¥ëœ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:
"""
{expanded}
"""
ì´ ì•„ì´ë””ì–´ë“¤ì— ëŒ€í•´ ë…¼ë¦¬ì /í˜„ì‹¤ì ì¸ ê´€ì ì—ì„œ ì•½ì ì´ë‚˜ ì£¼ì˜í•  ì ì„ ì§€ì í•´ì£¼ì„¸ìš”.


# brainstorm_assistant/prompts/mediator.txt
ë‹¤ìŒì€ í™•ì¥ëœ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:
"""
{expanded}
"""
ê·¸ë¦¬ê³  ì´ì— ëŒ€í•œ ë¹„íŒì…ë‹ˆë‹¤:
"""
{critique}
"""
ì–‘ì¸¡ì„ ì¡°ìœ¨í•˜ëŠ” ì¤‘ë¦½ì  ì˜ê²¬ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ì£¼ìš” ë…¼ì ì„ ìš”ì•½í•˜ê³  ì¡°ì • ë°©í–¥ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.


# brainstorm_assistant/prompts/summarizer.txt
- í™•ì¥ëœ ì•„ì´ë””ì–´:
"""
{expanded}
"""
- ë¹„íŒ:
"""
{critique}
"""
- ì¡°ìœ¨ëœ ì˜ê²¬:
"""
{mediated}
"""

ì´ íë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ì œì•ˆ ìš”ì•½ ë° ì‚¬ìš©ìê°€ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.


# brainstorm_assistant/requirements.txt
langchain
langgraph
openai
